# -*- coding: utf-8 -*-
import os
import sys
import pandas as pd
import numpy as np
import glob

"""
1. Get the number of (unique?) user IDs we have. This will be the row count of our matrix
2. Get the number of social landmarks. This will be the column count of the matrix
3. Populate with zeros (NumPy).
4. 
"""

#Going through the file for each social landmark that contains just the UserIDs for their
#followers, storing that list in a dataframe, which is stored within the list 
# 'sociallandmarkFollowers'. I actually want to redo this, I think... either turn into
# pandas Series or just into a dictionary, with key of social landmark name and value
#being a list of followerIDs.
# socialLandmarkFollowers = []
socialLandmarkFollowers = {}
for csvfile in glob.glob('sociallandmarks/*followerids.csv'):
    # socialLandmarkFollowers.append(pd.read_csv('csvfile', colnames = csvfile.strip('followerids.csv')))
    socialLandmarkHandle = csvfile[16:-15]
    socialLandmarkFollowers[socialLandmarkHandle] = pd.read_csv(csvfile)
    print socialLandmarkHandle
    #note: I don't think I'm doing the trim thing right here -- the key is that I want the
    #column name to be the sociallandmark name.
numberOfSocialLandmarks = len(socialLandmarkFollowers)
print numberOfSocialLandmarks

#Getting just the UserID column from my csv file that aggregates every csv of Search API
#results, generated by my readalltweets.py script. This might not be the way to go--
#might be better to take the code from that script and put it directly in here.
#Note that I'm including the drop_duplicates command -- for the purposes of this script,
#We don't care if we've gotten more than one tweet from someone, just if and how many
#Social landmarks the user follows
allUserIDs = pd.read_csv('concat.csv', usecols = ['UserID'], error_bad_lines = False, 
    warn_bad_lines = True)

tempdf = pd.read_csv('sociallandmarks/slfollowersNYbyLocationText.csv', 
    usecols = ['UserID'])

allUserIDs = allUserIDs.append(tempdf).drop_duplicates(['UserID'])

numberOfUserIDs = len(allUserIDs)

print numberOfUserIDs

# #creating a dataframe/matrix with a column for each social landmark and a row for each
# #UserID we've collected from the SearchAPI.
# data = pd.DataFrame(data=np.zeros((numberOfSocialLandmarks, numberOfUserIDs)), 
#     index=UserIDList, columns=SocialLandmarksList)


# #what I'm going through here is each userID we have from the search API, checking to see
# #if that UserID is in any of the sociallandmark follower lists by going through the
# #list of followers of each social landmark. Then I *need* to isolate the cell for the 
# # UserID, sociallandmark pair in my dataframe, and set the value from 0 to 1. The data.ix
# #function that I'm using here I think is right...reference page 127 in Python for Data
# #Analysis
# #Also, maybe do some sorting and binary searching here to determine if a userid is in
# #the social landmark list?
# for UserID in searchAPIUsers:
#     for socialLandmarkList in socialLandmarkFollowers:
#         if UserID in socialLandmarkList:
#             data.ix[UserID, sociallandmark] = 1
#         else:
#             continue



"""
OR We can do it Greg's way:
need to create a 16 x 1 million (or so, or however users I have) matrix, 
where each user is represented with a length 16 numpy array of 1s and 0s, standing 
for whether they follow each of the social landmarks. Also add a 1 million long numpy 
array of Trues and Falses, standing for whether they are a 'new yorker' by our 
estimation, and finally another million-long numpy array of the UserIDs. Obviously, 
these all need to be ordered the same way.
"""

matrix = np.zeros(numberOfSocialLandmarks, numberOfUserIDs)
sortedUserIDs = sort(searchAPIUsers)

for i in sortedUserIDs:
    socialLandmarkCount = 0
    for socialLandmark in socialLandmarkList:
        for j in socialLandmark:
            if i == j:
                matrix[socialLandmarkCount,i] = 1


